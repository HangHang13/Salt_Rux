2 이진판단 : 천체의 펄서 여부 판정 신경망
2.1 펄서 판정 문제
2.2 이진판단 문제의 신경망 처리
  이진판단은 예/아니오, 1/0 같은 두 가지 값 중 하나로 답하는 문제
  교차엔트로피, 시그모이드 함수이용
  
2.3 시그모이드함수
  범위에 제한 없는 임의의 실수값을 입력으로 받아 확률값의 범위에 해당하는 0과 1사이의 값을 출력하는 함수다.
  시그모이드 함수는 입력 x가 어떤 확률값의 로짓표현이라고 간주한다 
  로짓이란 실제 표현하려는 값을 로그값으로 대신 나타낸 것이다.
  
  s = 1/e^x+1
  
  시그모이드 함수는 입력 범위에 제한이 없으며 출력은 항상 0과 1사이의 값이다.
  입력이 커질 때, 출력은 1에, 입력이 작아질 때, 0에 수렴한다. 입력이 0일때 출력은 0.5이다.
  
2.4 확률 분포와 정보 엔트로피
 정보 엔트로피 : 확률 분포의 무질서도나 불확실성 혹은 정보 표현의 부담 정도를 나타내는 정보
 허프만코드 : 표현하려는 대상의 분포 비율을 조사해 자주 나타나는 대상에는 짧은 이진코드를, 간혹 나타나는 대상에는 긴 이진코드를 할당해 전체 표현에 필요한 비트수를 줄여주는 정보 압축 기법
 
2.5 확률 분포의 추정과 교차 엔트로피
  정보 엔트로피가 하나의 확률 분포가 갖는 불확실성 혹은 정보량을 정량적으로 계산할 수 있게하는 개념이라면 교차 엔트로피는 두 가지 확률 분포가 얼마나 비슷한지를 숫자 하나로 나타내는 개념이다.

2.6 딥러닝에서 교차엔트로피
  학슴 중이어서 수시로 수정되는 딥러닝 모델의 추정 확률 분포 P가 있고 이 딥러닝 모델이 흉내 내야 할 미지의 확률 분포 Q가 있다고 하자. Q와 P의 교차 엔트로피값을 계산할 수 있거나
  최소한 추정이라도 할 수 있다면 이 교차 엔트로피가 작아지는 쪽으로 P를 꾸준히 수정함으로써 확률 분포 P를 확률 분포 Q에 가깝개 접근시켜 갈 수 있다. 바로 이 점이 이진 판단에서
  신경망을 학습시킬 수 있는 원리가 된다. 하지만 실제 학습에는 논리적으로 두 가지 어려움이 있다.
  
  첫 번째, 애당초 확률 분포 Q를 정확하게 알고있지 못한 상태에서 Q와 P의 교차 엔트로피 값을 계산할 수 없다.
  두 번째, 확률 분포 Q는 고정된 확률 분포가 아니라, 입령에 따라 그때그때 달라지는 조건부 확률 분포라는 점이다.
  
  딥러닝 학습의 궁극적인 목표는 아직 접해보지 못한 새로운 입력에 대해서도 유사한 문제 풀ㄹ이 경험을 토대로 알맞은 답을 내어놓는 것이다.
  
  그런데 이진 판단 딥러닝에서는 입력에 대해 직접 출력을 추정하지 않는다. 대신 출력의 확률 분포, 즉 결과가 참 혹은 거짓일 가능성을 입력에 따른 조건부 확률 분포로서 추정한다.
  입력 데이터와 입력에 대한 출력값의 조건부 확률분포 사이에는 어떤 상관관계 패턴이 숨어 있을 것이다. 
  다양한 입출력 상에 대해 교차 엔트로피를 줄이는 학습을 반복하다 보면 이 숨어 있는 패턴이 신경망에 반영되면서 각각의 입력에
  알맞은 조건부 확률 분포를 적절하게 만들어낼 수 있게 될 것이다.
  
  이진판단 문제에서는 답 자체보다 답이 나오게 되는 확률 분포가 문제의 핵심이다.
  
2.7 시그모이드 교차 엔트로피와 편미분
 이진 판단 문제에 대한 학습 데이터의 정답으로 Z가 주어졌는데 신경망 회로는 로짓값 X를 출력했다고 하자.
 이떄 정답이 나타내는 확률 분포와 신경망이 추정하는 확률 분포 사이의 교차엔트로피를 구하면 다음과 같다
  
        H = x - xz + log(1+e^-x)
        
        
        
  
  
