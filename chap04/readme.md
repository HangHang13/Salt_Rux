제 4장 다층 퍼셉트론 기본 구조 : 세 가지 신경망의 재구성
4.1 다층 퍼셉트론 신경망 구조
  다층 퍼셉트론 신경망은 복수의 퍼셉트론 계층을 순서를 두고 배치하여 입력 벡터로부터 중간 표현을 거쳐 출력 벡터를 얻어내는 신경망 구조다. 간단히 다층 퍼셉트론이라고도 부른다..
  
  다층 퍼셉트론에서 각각의 계층은 단층 퍼셉트론과 같은 내부 구조를 가진다. 즉 하나의 계층안에 속한 퍼셉트론들은 동일한 입력을 공유하면서 각각 출력 성분을 만들어내지만 서로 어떤 연결도 없어
  영향을 주고 받을 수 없다. 하지만 이와 반대로 인접한 계층끼리는 앞 계층의 출력이 뒤 계층의 몸든 퍼셉트론에 공통 입력으로 제공된다. 즉 다층 퍼셉트론의 인접 계층끼리는 
  방향성을 갖는 완전 연결 방식으로 연결되는 것이다.
  
4.2 은닉 계층의 수와 폭
  다층 퍼셉트론에서 최종 단계에 배치된 계층은 신경망에 주어진 원래의 임무에 따라 알맞은 형태의 출력 벡터를 생성하는 역할을 맡는다. 그래서 출력 계층이라는 별도 이름을 가지며 출력 벡터의 크기,
  즉 출력 계층이 가질 퍼셉트론 수도 문제의 성격에 따라 고정적으로 정해진다.
  
  반면에 다층 퍼셉트론에서 새로 도입된 은닉 계층이 만들어낼 은닉 벡터에는 이런 제약이 없다. 따라서 출력 계층과 달리 은닉 계층의 수와 각 은닉 계층의 폭은 신경망 설계자가 자유롭게 정할 수 있다.
  여기에서 은닉 계층의 폭이란 해당 계층이 갖는 퍼셉트론 수이자 생성하는 은닉 벡터 크기를 말한다. 또한 퍼셉트론을 노드라고도 한다.
  
  한 계층의 퍼셉트론들은 각각 해당 계층에 대한 입력 벡터 크기만큼 가중치와 하나의 편향 파라미터를 갖는다. 
  입력 m개에 연결된 퍼셉트론 n개를 갖는 한 계층이 파라미터 수는  m * n 개의 가중치 파라미터와 n 개의 편향 파라미터를 합쳐 m * n + n 개가 된다.
  
  은닉 계층의 수와 각 은닉 계층의 폭은 신경망의 품질을 결정짓는 중요한 요인이 될 수 있지만 무조건 은닉 계층 수나 폭을 늘린다고 품질이 좋아지는 것은 아니다.
  은닉 계층을 추가해 파라미터 수가 늘어나면 더 많은 학습 데이터가 필요해지는 경향이 있다. 따라서 충분한 양의 양질의 데이터가 준비되지 않으면 다층 퍼셉트론 구조의 확장은 오히려
  신경망 품질을 떨어뜨릴 수 있다.
  
  은닉 계층 수와 폭은 문제의 규모, 데이터양, 난이도를 종합적으로 고려해 정해야 한다. 그래서 다양한 실험과 축적된 경험이 중요하다. 이때 학습률이나 미니배치 크기 같은
  다른 하이퍼파라미터도 중요한 영향을 미칠 수 있으므로 유의해야 한다. 따라서 다층 퍼셉트론을 도입할 때는 은닉 계층 수와 폭 설정값을 쉽게 바꾸어가며 실험할 수 있게 프로그램을 구현해야한다.
  
  
4.3 비선형 활성화 함수
  은닉 계층은 가중치와 편향을 이용해 계산된 선형 연산 결과를 바로 출력으로 내보내는 대신 한 번 더 변형시켜 내보낸다. 선형 연산 결과 뒷단에 적용되어 퍼셉트론의 출력을 변형시키려고
  추가한 장치를 비선형 활성화 함수라고 한다. 선형 연산 결과는 곱셈과 덧셈으로만 이루어지는 선형 연산의 특정상 항상 입력의 일차 함수로 나타나게 마련이다. 비선형 함수는 일차함수로 표현이 불가능한
  좀 더 복잡한 기능을 수행하는 함수다. 따라서 비선형 활성화 함수를 추가하면 입력의 일차 함수 표현을 넘어서는 다양하고 복잡한 형태의 퍼셉트론 출력을 만들 수 있다. 
  
  ++++++++++++++++++++++++++++++++++++
